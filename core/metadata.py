"""
ë©”íƒ€ë°ì´í„° ë¶„ì„ ëª¨ë“ˆ (v2.0 ì‹ ê·œ)
PNG, JPEG íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ìˆ¨ê²¨ì§„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- PNG ì²­í¬ ë¶„ì„ (zTXt, tEXt, iTXt)
- EXIF ë°ì´í„° ì¶”ì¶œ
- ì••ì¶•ëœ ë©”íƒ€ë°ì´í„° í•´ì œ
- CTF ë¬¸ì œ: Hit a Brick Wall í•´ê²°
"""

import struct
import zlib
import base64
from typing import Dict, List, Optional, Any, Tuple
from PIL import Image
from PIL.ExifTags import TAGS, GPSTAGS
import os
import re


class MetadataAnalyzer:
    """ë©”íƒ€ë°ì´í„° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.supported_formats = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
    
    def analyze_file(self, file_path: str) -> Dict[str, Any]:
        """íŒŒì¼ì˜ ëª¨ë“  ë©”íƒ€ë°ì´í„°ë¥¼ ë¶„ì„"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        file_ext = os.path.splitext(file_path)[1].lower()
        
        results = {
            'file_path': file_path,
            'file_size': os.path.getsize(file_path),
            'format': file_ext,
            'metadata': {},
            'hidden_data': [],
            'suspicious_patterns': []
        }
        
        if file_ext == '.png':
            results.update(self.analyze_png(file_path))
        elif file_ext in ['.jpg', '.jpeg']:
            results.update(self.analyze_jpeg(file_path))
        else:
            results.update(self.analyze_generic_exif(file_path))
            
        return results
    
    def analyze_png(self, file_path: str) -> Dict[str, Any]:
        """PNG íŒŒì¼ì˜ ì²­í¬ êµ¬ì¡°ë¥¼ ë¶„ì„"""
        print(f"ğŸ” PNG íŒŒì¼ ë¶„ì„ ì¤‘: {file_path}")
        
        with open(file_path, 'rb') as f:
            data = f.read()
        
        # PNG ì‹œê·¸ë‹ˆì²˜ í™•ì¸
        if data[:8] != b'\x89PNG\r\n\x1a\n':
            raise ValueError("ìœ íš¨í•œ PNG íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤")
        
        chunks = self._parse_png_chunks(data)
        metadata = {}
        hidden_data = []
        suspicious = []
        
        # ê° ì²­í¬ íƒ€ì…ë³„ ì²˜ë¦¬
        for chunk in chunks:
            chunk_type = chunk['type']
            chunk_data = chunk['data']
            
            if chunk_type == 'zTXt':
                # ì••ì¶•ëœ í…ìŠ¤íŠ¸ ì²­í¬ (Hit a Brick Wall í•´ê²°!)
                result = self._process_ztxt_chunk(chunk_data)
                metadata['zTXt'] = result
                if result.get('decompressed_data'):
                    hidden_data.append({
                        'source': 'zTXt chunk',
                        'data': result['decompressed_data'],
                        'compressed': True
                    })
                    suspicious.append("zTXt ì²­í¬ì—ì„œ ì••ì¶•ëœ ë°ì´í„° ë°œê²¬")
            
            elif chunk_type == 'tEXt':
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²­í¬
                result = self._process_text_chunk(chunk_data)
                metadata['tEXt'] = result
                if result.get('value'):
                    hidden_data.append({
                        'source': 'tEXt chunk',
                        'data': result['value'],
                        'compressed': False
                    })
            
            elif chunk_type == 'iTXt':
                # êµ­ì œí™” í…ìŠ¤íŠ¸ ì²­í¬
                result = self._process_itext_chunk(chunk_data)
                metadata['iTXt'] = result
                if result.get('text'):
                    hidden_data.append({
                        'source': 'iTXt chunk',
                        'data': result['text'],
                        'compressed': result.get('compressed', False)
                    })
            
            elif chunk_type in ['IHDR', 'PLTE', 'IDAT', 'IEND']:
                # í•„ìˆ˜ ì²­í¬ë“¤
                metadata[chunk_type] = self._process_standard_chunk(chunk_type, chunk_data)
            
            else:
                # ê¸°íƒ€ ë³´ì¡° ì²­í¬ë“¤
                metadata[chunk_type] = {
                    'size': len(chunk_data),
                    'raw_data': chunk_data[:100].hex() if len(chunk_data) > 100 else chunk_data.hex()
                }
                if chunk_type not in ['bKGD', 'cHRM', 'gAMA', 'hIST', 'pHYs', 'sBIT', 'tIME', 'tRNS']:
                    suspicious.append(f"ë¹„í‘œì¤€ ì²­í¬ ë°œê²¬: {chunk_type}")
        
        return {
            'png_chunks': chunks,
            'metadata': metadata,
            'hidden_data': hidden_data,
            'suspicious_patterns': suspicious
        }
    
    def _parse_png_chunks(self, data: bytes) -> List[Dict[str, Any]]:
        """PNG ì²­í¬ êµ¬ì¡° íŒŒì‹±"""
        chunks = []
        pos = 8  # PNG ì‹œê·¸ë‹ˆì²˜ ê±´ë„ˆë›°ê¸°
        
        while pos < len(data):
            if pos + 8 > len(data):
                break
                
            # ê¸¸ì´ (4ë°”ì´íŠ¸)
            length = struct.unpack('>I', data[pos:pos+4])[0]
            pos += 4
            
            # íƒ€ì… (4ë°”ì´íŠ¸)
            chunk_type = data[pos:pos+4].decode('ascii', errors='ignore')
            pos += 4
            
            # ë°ì´í„°
            chunk_data = data[pos:pos+length] if length > 0 else b''
            pos += length
            
            # CRC (4ë°”ì´íŠ¸)
            crc = struct.unpack('>I', data[pos:pos+4])[0] if pos + 4 <= len(data) else 0
            pos += 4
            
            chunks.append({
                'type': chunk_type,
                'length': length,
                'data': chunk_data,
                'crc': crc
            })
            
            # IEND ì²­í¬ì—ì„œ ì¢…ë£Œ
            if chunk_type == 'IEND':
                break
        
        return chunks
    
    def _process_ztxt_chunk(self, data: bytes) -> Dict[str, Any]:
        """zTXt ì²­í¬ ì²˜ë¦¬ (ì••ì¶•ëœ í…ìŠ¤íŠ¸) - Hit a Brick Wall í•µì‹¬!"""
        try:
            # zTXt í˜•ì‹: keyword\0compression_method + compressed_text
            null_pos = data.find(b'\x00')
            if null_pos == -1:
                return {'error': 'null êµ¬ë¶„ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ'}
            
            keyword = data[:null_pos].decode('latin1')
            
            # ì••ì¶• ë°©ë²• (1ë°”ì´íŠ¸)
            if null_pos + 1 >= len(data):
                return {'error': 'ì••ì¶• ë°©ë²• ë°”ì´íŠ¸ ì—†ìŒ'}
            
            compression_method = data[null_pos + 1]
            compressed_data = data[null_pos + 2:]
            
            # zlib ì••ì¶• í•´ì œ
            if compression_method == 0:  # zlib ì••ì¶•
                try:
                    decompressed = zlib.decompress(compressed_data)
                    decompressed_text = decompressed.decode('utf-8', errors='ignore')
                    
                    return {
                        'keyword': keyword,
                        'compression_method': compression_method,
                        'compressed_size': len(compressed_data),
                        'decompressed_size': len(decompressed),
                        'decompressed_data': decompressed_text,
                        'raw_decompressed': decompressed
                    }
                except Exception as e:
                    return {
                        'keyword': keyword,
                        'compression_method': compression_method,
                        'error': f'ì••ì¶• í•´ì œ ì‹¤íŒ¨: {str(e)}',
                        'raw_compressed': compressed_data[:100].hex()
                    }
            else:
                return {
                    'keyword': keyword,
                    'compression_method': compression_method,
                    'error': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” ì••ì¶• ë°©ë²•: {compression_method}'
                }
        
        except Exception as e:
            return {'error': f'zTXt ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}
    
    def _process_text_chunk(self, data: bytes) -> Dict[str, Any]:
        """tEXt ì²­í¬ ì²˜ë¦¬ (ì¼ë°˜ í…ìŠ¤íŠ¸)"""
        try:
            null_pos = data.find(b'\x00')
            if null_pos == -1:
                return {'error': 'null êµ¬ë¶„ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ'}
            
            keyword = data[:null_pos].decode('latin1')
            value = data[null_pos + 1:].decode('latin1', errors='ignore')
            
            return {
                'keyword': keyword,
                'value': value
            }
        except Exception as e:
            return {'error': f'tEXt ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}
    
    def _process_itext_chunk(self, data: bytes) -> Dict[str, Any]:
        """iTXt ì²­í¬ ì²˜ë¦¬ (êµ­ì œí™” í…ìŠ¤íŠ¸)"""
        try:
            # iTXt í˜•ì‹: keyword\0compression_flag\0compression_method\0language_tag\0translated_keyword\0text
            parts = data.split(b'\x00', 4)
            if len(parts) < 5:
                return {'error': 'iTXt í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ'}
            
            keyword = parts[0].decode('utf-8', errors='ignore')
            compression_flag = parts[1][0] if len(parts[1]) > 0 else 0
            compression_method = parts[2][0] if len(parts[2]) > 0 else 0
            language_tag = parts[3].decode('utf-8', errors='ignore')
            translated_keyword = parts[4].decode('utf-8', errors='ignore')
            
            # ë‚˜ë¨¸ì§€ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°
            text_data = data[len(parts[0]) + len(parts[1]) + len(parts[2]) + len(parts[3]) + len(parts[4]) + 5:]
            
            if compression_flag == 1 and compression_method == 0:
                # ì••ì¶•ëœ í…ìŠ¤íŠ¸
                try:
                    text = zlib.decompress(text_data).decode('utf-8', errors='ignore')
                except:
                    text = text_data.decode('utf-8', errors='ignore')
            else:
                text = text_data.decode('utf-8', errors='ignore')
            
            return {
                'keyword': keyword,
                'compression_flag': compression_flag,
                'compression_method': compression_method,
                'language_tag': language_tag,
                'translated_keyword': translated_keyword,
                'text': text,
                'compressed': compression_flag == 1
            }
        except Exception as e:
            return {'error': f'iTXt ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}
    
    def _process_standard_chunk(self, chunk_type: str, data: bytes) -> Dict[str, Any]:
        """í‘œì¤€ PNG ì²­í¬ ì²˜ë¦¬"""
        if chunk_type == 'IHDR':
            # ì´ë¯¸ì§€ í—¤ë”
            if len(data) >= 13:
                width, height, bit_depth, color_type, compression, filter_method, interlace = struct.unpack('>IIBBBBB', data)
                return {
                    'width': width,
                    'height': height,
                    'bit_depth': bit_depth,
                    'color_type': color_type,
                    'compression': compression,
                    'filter_method': filter_method,
                    'interlace': interlace
                }
        elif chunk_type == 'IDAT':
            # ì´ë¯¸ì§€ ë°ì´í„°
            return {
                'size': len(data),
                'compressed_image_data': True
            }
        elif chunk_type == 'IEND':
            # íŒŒì¼ ë
            return {'end_of_file': True}
        
        return {
            'size': len(data),
            'raw_data': data[:50].hex() if len(data) > 50 else data.hex()
        }
    
    def search_for_flags(self, analysis_result: Dict[str, Any]) -> List[str]:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ CTF í”Œë˜ê·¸ íŒ¨í„´ ê²€ìƒ‰"""
        flags = []
        flag_patterns = [
            r'flag\{[^}]+\}',
            r'FLAG\{[^}]+\}', 
            r'CTF\{[^}]+\}',
            r'ctf\{[^}]+\}'
        ]
        
        # ìˆ¨ê²¨ì§„ ë°ì´í„°ì—ì„œ ê²€ìƒ‰
        for hidden in analysis_result.get('hidden_data', []):
            data = str(hidden.get('data', ''))
            for pattern in flag_patterns:
                matches = re.findall(pattern, data, re.IGNORECASE)
                flags.extend(matches)
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ê²€ìƒ‰
        def search_in_dict(d):
            if isinstance(d, dict):
                for v in d.values():
                    search_in_dict(v)
            elif isinstance(d, str):
                for pattern in flag_patterns:
                    matches = re.findall(pattern, d, re.IGNORECASE)
                    flags.extend(matches)
            elif isinstance(d, list):
                for item in d:
                    search_in_dict(item)
        
        search_in_dict(analysis_result.get('metadata', {}))
        
        return list(set(flags))  # ì¤‘ë³µ ì œê±°


def main():
    """ë©”íƒ€ë°ì´í„° ë¶„ì„ ë„êµ¬ í…ŒìŠ¤íŠ¸"""
    analyzer = MetadataAnalyzer()
    
    # Hit a Brick Wall CTF ë¬¸ì œ í…ŒìŠ¤íŠ¸
    test_file = "CTF-ë¬¸ì œ-ì‚¬ì§„/hit_a_brick_wall/bricks.png"
    
    if os.path.exists(test_file):
        print("ğŸ¯ Hit a Brick Wall CTF ë¬¸ì œ ë¶„ì„ ì‹œì‘")
        print("=" * 60)
        
        result = analyzer.analyze_file(test_file)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"ğŸ“ íŒŒì¼: {result['file_path']}")
        print(f"ğŸ“Š í¬ê¸°: {result['file_size']:,} ë°”ì´íŠ¸")
        print(f"ğŸ¨ í˜•ì‹: {result['format']}")
        print()
        
        # ìˆ¨ê²¨ì§„ ë°ì´í„°
        if result['hidden_data']:
            print("ğŸ” ë°œê²¬ëœ ìˆ¨ê²¨ì§„ ë°ì´í„°:")
            for i, data in enumerate(result['hidden_data'], 1):
                print(f"  {i}. ì¶œì²˜: {data['source']}")
                print(f"     ë°ì´í„°: {data['data'][:200]}...")
                print()
        
        # í”Œë˜ê·¸ ê²€ìƒ‰
        flags = analyzer.search_for_flags(result)
        if flags:
            print("ğŸš© ë°œê²¬ëœ í”Œë˜ê·¸:")
            for flag in flags:
                print(f"  âœ… {flag}")
        else:
            print("âŒ í”Œë˜ê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        print("\n" + "=" * 60)
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")


if __name__ == "__main__":
    main()